{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/opinion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Downloading books is easy, the screen is NOT too dark, the font size is adjustable and the Kindle customer service support is terrific.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentence.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(df.Sentence.values)\n",
    "# sentences = [sent for sent in parsed_opinions.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 14834/14834 [08:34<00:00, 28.81it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp_sentences = []\n",
    "for sentence in tqdm(sentences):\n",
    "    nlp_sentences.append(nlp(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nlp_sentences[0]\n",
    "for i in test:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('$',\n",
       " \"''\",\n",
       " ',',\n",
       " '-LRB-',\n",
       " '-RRB-',\n",
       " '.',\n",
       " ':',\n",
       " 'ADD',\n",
       " 'AFX',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'HYPH',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'LS',\n",
       " 'MD',\n",
       " 'NFP',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'POS',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'SYM',\n",
       " 'TO',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WP$',\n",
       " 'WRB',\n",
       " 'XX',\n",
       " '_SP',\n",
       " '``')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.tagger.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('$',\n",
       " \"''\",\n",
       " ',',\n",
       " '-LRB-',\n",
       " '-RRB-',\n",
       " '.',\n",
       " ':',\n",
       " 'ADD',\n",
       " 'AFX',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'HYPH',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'LS',\n",
       " 'MD',\n",
       " 'NFP',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'POS',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'SYM',\n",
       " 'TO',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WP$',\n",
       " 'WRB',\n",
       " 'XX',\n",
       " '_SP',\n",
       " '``')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.tagger.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14834it [00:00, 24578.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# tags = list(nlp.tagger.labels)\n",
    "# tags_dict = {tag: i for i, tag in enumerate(tags)}\n",
    "\n",
    "# for index, sent in tqdm(enumerate(nlp_sentences)):\n",
    "#     vals = [0 for _ in range(len(tags))]\n",
    "#     for token in sent:\n",
    "#         vals[tags_dict[token.tag_]] += 1\n",
    "#     features[index] = vals\n",
    "    \n",
    "\n",
    "pars = list(nlp.parser.labels) + list(nlp.tagger.labels)\n",
    "pars_dict = {par: i for i, par in enumerate(pars)}\n",
    "features = np.zeros((len(nlp_sentences), len(pars)))\n",
    "errors = 0\n",
    "for index, sent in tqdm(enumerate(nlp_sentences)):\n",
    "    vals = [0 for _ in range(len(pars))]\n",
    "    for token in sent:\n",
    "        vals[pars_dict[token.tag_]] += 1\n",
    "        try:\n",
    "            vals[pars_dict[token.dep_]] += 1\n",
    "        except:\n",
    "            errors += 1\n",
    "            continue\n",
    "    features[index] = vals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df.Opinion.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import operator\n",
    "import json\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.33, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=500, oob_score=True, n_jobs=-1,random_state=50, max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf_classifier.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== Results ===================\n",
      "            Fact     Opinion                   \n",
      "F1       [0.8914405  0.89604158]\n",
      "Precision[0.898191   0.88963875]\n",
      "Recall   [0.88479072 0.90253725]\n",
      "Accuracy 0.8937908496732027\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "list_of_labels = sorted(list(set(y_train)))\n",
    "precision = precision_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "recall = recall_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "print(\"=================== Results ===================\")\n",
    "print(\"            Fact     Opinion                   \")\n",
    "print(\"F1       \" + str(f1))\n",
    "print(\"Precision\" + str(precision))\n",
    "print(\"Recall   \" + str(recall))\n",
    "print(\"Accuracy \" + str(accuracy))\n",
    "print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf_classifier.fit(features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/disney_reviews.json') as f:\n",
    "    reviews = json.load(f)\n",
    "\n",
    "docs = reviews['Frozen II']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [sent_tokenize(doc) for doc in docs]\n",
    "docs = [x for sublist in docs for x in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 9677/9677 [01:44<00:00, 92.42it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp_sentences_new = []\n",
    "for sentence in tqdm(docs):\n",
    "    nlp_sentences_new.append(nlp(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9677it [00:00, 24186.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# tags = list(nlp.tagger.labels)\n",
    "# tags_dict = {tag: i for i, tag in enumerate(tags)}\n",
    "# new_features = np.zeros((len(docs), len(tags)))\n",
    "\n",
    "# for index, sent in tqdm(enumerate(nlp_sentences_new)):\n",
    "#     vals = [0 for _ in range(len(tags))]\n",
    "#     for token in sent:\n",
    "#         vals[tags_dict[token.tag_]] += 1\n",
    "#     new_features[index] = vals\n",
    "\n",
    "pars = list(nlp.parser.labels) + list(nlp.tagger.labels)\n",
    "pars_dict = {par: i for i, par in enumerate(pars)}\n",
    "new_features = np.zeros((len(nlp_sentences_new), len(pars)))\n",
    "errors = 0\n",
    "for index, sent in tqdm(enumerate(nlp_sentences_new)):\n",
    "    vals = [0 for _ in range(len(pars))]\n",
    "    for token in sent:\n",
    "        vals[pars_dict[token.tag_]] += 1\n",
    "        try:\n",
    "            vals[pars_dict[token.dep_]] += 1\n",
    "        except:\n",
    "            errors += 1\n",
    "            continue\n",
    "    new_features[index] = vals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.332     , 0.668     ],\n",
       "       [0.12311111, 0.87688889],\n",
       "       [0.426     , 0.574     ],\n",
       "       ...,\n",
       "       [0.87      , 0.13      ],\n",
       "       [0.96      , 0.04      ],\n",
       "       [0.534     , 0.466     ]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2195"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.824 0.176\n",
      "When a story is about two of more different cultures, and one of the cultures is what we associate with Europa, Disney have a bad habit of portraying the latter in a negative light, and take liberties like turning medieval settings into modern day rainbow coalitions.\n",
      "\n",
      "\n",
      "0.11266666666666666 0.8873333333333333\n",
      "The plot was soo thin with no purpose.\n",
      "\n",
      "\n",
      "0.8392627594627595 0.16073724053724056\n",
      "The songs were atrocious !!\n",
      "\n",
      "\n",
      "0.818 0.182\n",
      "The songs are really nothing to write home about.\n",
      "\n",
      "\n",
      "0.187 0.8130000000000002\n",
      "It was just basic.\n",
      "\n",
      "\n",
      "0.828 0.172\n",
      "We both fell asleep wishing the nightmare would end so we could leave.\n",
      "\n",
      "\n",
      "0.012 0.988\n",
      "This.\n",
      "\n",
      "\n",
      "0.942 0.058\n",
      "All the negative reviews I see complain about it either being too dark or all over the place.\n",
      "\n",
      "\n",
      "0.17733333333333334 0.8226666666666667\n",
      "It was neither.\n",
      "\n",
      "\n",
      "0.93 0.07\n",
      "When you pay four times as much for concessions in a movie theater than you would pay in a store for candy, I would like to feel as if the level of entertainment was higher in the theater, but frankly I feel that people watching in a supermarket would be more stimulating than this lame story.\n",
      "\n",
      "\n",
      "0.996 0.004\n",
      "What happened to the music?\n",
      "\n",
      "\n",
      "0.896 0.104\n",
      "The first was truly great for the music, scores, themes and vocals, this one; \"pity that didn't have a song like the first one\" was a comment from someone leaving the theater.\n",
      "\n",
      "\n",
      "0.9413333333333334 0.058666666666666666\n",
      "The original Frozen was brilliant, but this doesn't come anywhere near it.\n",
      "\n",
      "\n",
      "0.111 0.889\n",
      "Watch something better.\n",
      "\n",
      "\n",
      "0.882 0.118\n",
      "They struck gold with Let It Go therefore they just threw in a few dozen of unnecessary songs to see which one becomes another hit.\n",
      "\n",
      "\n",
      "0.178 0.822\n",
      "Unmeaningful and the voice overs didnt match the charcters attiude.\n",
      "\n",
      "\n",
      "0.1455 0.8545\n",
      "Overall absolute garbage.\n",
      "\n",
      "\n",
      "0.024 0.976\n",
      "The animation in Frozen II is stunning.\n",
      "\n",
      "\n",
      "0.832 0.168\n",
      "The worst script writing in an animation I have ever seen, with awful lines such as 'let me see what I can see', and 'i love you with all that i am'.\n",
      "\n",
      "\n",
      "0.84 0.16\n",
      "The attention to detail is breathtaking and it really draws into the movie.\n",
      "\n",
      "\n",
      "0.854 0.146\n",
      "As soon as I heard about the \"5th spirit\" I instantly knew it was Elsa, AKA The Avatar (yeah, I know she can't control all Elements, but I'm sure they would've liked to do that aswell, wouldn't it retcon the first movie).\n",
      "\n",
      "\n",
      "0.812 0.188\n",
      "Also, the main story of \"We thought our ancestor (or whoever) were good people, but they were actually bad\" is also something we've seen SO MANY TIMES before, so that part was very predicatable too.\n",
      "\n",
      "\n",
      "0.828 0.172\n",
      "(If you want to tell me that you thought Elsa was actually dead, you're a liar.)\n",
      "\n",
      "\n",
      "0.088 0.912\n",
      "Just go see it\n",
      "\n",
      "\n",
      "0.15379285714285715 0.8462071428571429\n",
      "This movie was absolutely stunning!\n",
      "\n",
      "\n",
      "0.102 0.898\n",
      "The story was beautiful and so was the movie itself.\n",
      "\n",
      "\n",
      "0.852 0.148\n",
      "I still don't get what happened, except that Elsa followed her calling.\n",
      "\n",
      "\n",
      "0.922 0.078\n",
      "They rush into this new story with the trolls giving a very blah warning, you can tell the writers half-assed it so that more songs can get jammed into it.\n",
      "\n",
      "\n",
      "0.876 0.124\n",
      "As far as I'm concerned there was only one 'Frozen' film, going to choose to ignore this sequel like I do with the other failed Disney sequels .\n",
      "\n",
      "\n",
      "0.176 0.824\n",
      "I would def.\n",
      "\n",
      "\n",
      "0.904 0.096\n",
      "Recommend this movie if you liked the 1st one!\n",
      "\n",
      "\n",
      "0.8606666666666667 0.1393333333333333\n",
      "The characters from Frozen are awesome!\n",
      "\n",
      "\n",
      "0.996 0.004\n",
      "Disney decides to unnecessarily preach to us about reparations, while dangling it's liberal propaganda in our faces and then distracting us with witty humor.\n",
      "\n",
      "\n",
      "1.0 0.0\n",
      "It is getting so ridiculous.\n",
      "\n",
      "\n",
      "0.094 0.906\n",
      "What can I say, it's garbage!\n",
      "\n",
      "\n",
      "0.876 0.124\n",
      "Well, one man's garbage maybe another man's treasure; some kids probably love it.\n",
      "\n",
      "\n",
      "1.0 0.0\n",
      "No; he did not.\n",
      "\n",
      "\n",
      "0.101 0.899\n",
      "😑😣\n",
      "\n",
      "\n",
      "0.18910000000000002 0.8109000000000001\n",
      "Writing a review for the first time.\n",
      "\n",
      "\n",
      "0.002 0.998\n",
      "Dont go!\n",
      "\n",
      "\n",
      "0.0 1.0\n",
      "!\n",
      "\n",
      "\n",
      "0.196 0.804\n",
      "My god I could go on for ages!\n",
      "\n",
      "\n",
      "0.942495670995671 0.057504329004329\n",
      "All you have to do is listen\n",
      "\n",
      "\n",
      "0.864 0.136\n",
      "Maybe they should take a lesson from the musical team of Moana, which was more than awesome.\n",
      "\n",
      "\n",
      "0.032 0.968\n",
      "Very terrible .\n",
      "\n",
      "\n",
      "0.884 0.116\n",
      "These strengths made Elsa had to live her life as a runaway, before finally returning to Arendelle thanks to Anna's struggle and hard work.\n",
      "\n",
      "\n",
      "0.842 0.158\n",
      "Elsa and Anna's adventure in Frozen 2 began with Elsa's curiosity about a mysterious song that seemed to keep calling her from the north.\n",
      "\n",
      "\n",
      "0.932 0.068\n",
      "You have to watch it so that all your questions are answered ...\n",
      "\n",
      "\n",
      "0.996 0.004\n",
      "I can stretch my mind to make sense of this very confusing movie or at least very confusing parts.\n",
      "\n",
      "\n",
      "0.828 0.172\n",
      "Ask your child afterwards about the movie and what they got out of it.\n",
      "\n",
      "\n",
      "0.02579047619047619 0.9742095238095237\n",
      "Good animation.\n",
      "\n",
      "\n",
      "0.958 0.042\n",
      "DON\"T GO!!!!!!!\n",
      "\n",
      "\n",
      "0.0 1.0\n",
      "!\n",
      "\n",
      "\n",
      "0.832 0.168\n",
      "Nothing really changes from the first to the second movie.\n",
      "\n",
      "\n",
      "0.872 0.128\n",
      "The plot holes are 30 something years wide.\n",
      "\n",
      "\n",
      "0.08153333333333335 0.9184666666666665\n",
      "Very disappointing, this movie was pretty boring and was so dark.\n",
      "\n",
      "\n",
      "0.932 0.068\n",
      "Granted, these movies always have some type of \"magic\" in them but they went way off the deep end with this one, focusing on the \"spirits\" and powers and just didn't make any sense.\n",
      "\n",
      "\n",
      "0.026 0.974\n",
      "Please.\n",
      "\n",
      "\n",
      "0.12266666666666667 0.8773333333333333\n",
      "Everything else.\n",
      "\n",
      "\n",
      "0.8172995670995672 0.1827004329004329\n",
      "The story was completely incoherent.\n",
      "\n",
      "\n",
      "0.184 0.816\n",
      "The first 15 minutes was funny, cute and engaging.\n",
      "\n",
      "\n",
      "0.882 0.118\n",
      "the last 10 minutes was at least exciting and adventurous, but by the time we got there, I didn't even care any more.\n",
      "\n",
      "\n",
      "0.086 0.914\n",
      "What a disappointment!\n",
      "\n",
      "\n",
      "0.07954285714285717 0.9204571428571426\n",
      "Too many mediocre songs and not enough Story.\n",
      "\n",
      "\n",
      "0.12366666666666667 0.8763333333333334\n",
      "Waaaay too much singing.\n",
      "\n",
      "\n",
      "0.185 0.815\n",
      "Overall, not worth my money and time!\n",
      "\n",
      "\n",
      "0.006 0.994\n",
      "Yucky movie.\n",
      "\n",
      "\n",
      "0.908 0.092\n",
      "I'm sad I wasted my money on this movie as well as my time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index, val in enumerate(predictions[200:500]):\n",
    "    if val[0] > .8 or val[1] > .8:\n",
    "        print()\n",
    "        print(val[0], val[1])\n",
    "        print(nlp_sentences_new[200+index])\n",
    "        print()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
